# SOME DESCRIPTIVE TITLE
# Copyright (C) YEAR Free Software Foundation, Inc.
# This file is distributed under the same license as the PACKAGE package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PACKAGE VERSION\n"
"POT-Creation-Date: 2020-12-29 14:10+0900\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: \n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#. This guide is maintained in the main Quarkus repository
#. and pull requests should be submitted there:
#. https://github.com/quarkusio/quarkus/tree/master/docs/src/main/asciidoc
#. type: Title =
#: upstream/_guides/kafka-streams.adoc:6
#, no-wrap
msgid "Quarkus - Using Apache Kafka Streams"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:11
msgid ""
"This guide demonstrates how your Quarkus application can utilize the Apache "
"Kafka Streams API to implement stream processing applications based on "
"Apache Kafka."
msgstr ""

#. type: Title ==
#: upstream/_guides/kafka-streams.adoc:12
#, no-wrap
msgid "Prerequisites"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:15
msgid "To complete this guide, you need:"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:17
msgid "less than 30 minutes"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:18
msgid "an IDE"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:19
msgid "JDK 1.8+ installed with `JAVA_HOME` configured appropriately"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:20
msgid "Apache Maven {maven-version}"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:21
msgid "Docker Compose to start an Apache Kafka development cluster"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:22
msgid "GraalVM installed if you want to run in native mode."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:24
msgid ""
"It is recommended, that you have read the "
"{quickstarts-tree-url}/kafka-quickstart[Kafka quickstart] before."
msgstr ""

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:29
msgid ""
"The Quarkus extension for Kafka Streams allows for very fast turnaround "
"times during development by supporting the Quarkus Dev Mode (e.g. via "
"`./mvnw compile quarkus:dev`).  After changing the code of your Kafka "
"Streams topology, the application will automatically be reloaded when the "
"next input message arrives."
msgstr ""

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:32
msgid ""
"A recommended development set-up is to have some producer which creates test "
"messages on the processed topic(s) in fixed intervals, e.g. every second and "
"observe the streaming application's output topic(s) using a tool such as "
"`kafkacat`.  Using the dev mode, you'll instantly see messages on the output "
"topic(s) as produced by the latest version of your streaming application "
"when saving."
msgstr ""

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:34
msgid ""
"For the best development experience, we recommend applying the following "
"configuration settings to your Kafka broker:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:38
#, no-wrap
msgid "group.min.session.timeout.ms=250\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:41
msgid ""
"Also specify the following settings in your Quarkus "
"`application.properties`:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:46
#, no-wrap
msgid ""
"kafka-streams.consumer.session.timeout.ms=250\n"
"kafka-streams.consumer.heartbeat.interval.ms=200\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:49
msgid ""
"Together, these settings will ensure that the application can very quickly "
"reconnect to the broker after being restarted in dev mode."
msgstr ""

#. type: Named 'alt' AttributeList argument for macro 'image'
#: upstream/_guides/kafka-streams.adoc:51 upstream/_guides/kafka-streams.adoc:69 upstream/_guides/kafka-streams.adoc:807
#, no-wrap
msgid "Architecture"
msgstr ""

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:56
msgid ""
"In this guide, we are going to generate (random) temperature values in one "
"component (named `generator`).  These values are associated to given weather "
"stations and are written in a Kafka topic (`temperature-values`).  Another "
"topic (`weather-stations`) contains just the master data about the weather "
"stations themselves (id and name)."
msgstr ""

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:58
msgid ""
"A second component (`aggregator`) reads from the two Kafka topics and "
"processes them in a streaming pipeline:"
msgstr ""

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:60
msgid "the two topics are joined on weather station id"
msgstr ""

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:61
msgid "per weather station the min, max and average temperature is determined"
msgstr ""

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:62
msgid ""
"this aggregated data is written out to a third topic "
"(`temperatures-aggregated`)"
msgstr ""

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:66
msgid ""
"The data can be examined by inspecting the output topic.  By exposing a "
"Kafka Streams "
"https://kafka.apache.org/22/documentation/streams/developer-guide/interactive-queries.html[interactive "
"query], the latest result for each weather station can alternatively be "
"obtained via a simple REST query."
msgstr ""

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:68
msgid "The overall architecture looks like so:"
msgstr ""

#. type: Target for macro image
#: upstream/_guides/kafka-streams.adoc:69
#, no-wrap
msgid "kafka-streams-guide-architecture.png"
msgstr ""

#. type: Title ==
#: upstream/_guides/kafka-streams.adoc:71
#, no-wrap
msgid "Solution"
msgstr ""

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:75
msgid ""
"We recommend that you follow the instructions in the next sections and "
"create the application step by step.  However, you can go right to the "
"completed example."
msgstr ""

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:77
msgid ""
"Clone the Git repository: `git clone {quickstarts-clone-url}`, or download "
"an {quickstarts-archive-url}[archive]."
msgstr ""

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:79
msgid ""
"The solution is located in the `kafka-streams-quickstart` "
"{quickstarts-tree-url}/kafka-streams-quickstart[directory]."
msgstr ""

#. type: Title ==
#: upstream/_guides/kafka-streams.adoc:80
#, no-wrap
msgid "Creating the Producer Maven Project"
msgstr ""

#. type: delimited block =
#: upstream/_guides/kafka-streams.adoc:84
msgid ""
"First, we need a new project with the temperature value producer.  Create a "
"new project with the following command:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:93
#, no-wrap
msgid ""
"mvn io.quarkus:quarkus-maven-plugin:{quarkus-version}:create \\\n"
"    -DprojectGroupId=org.acme \\\n"
"    -DprojectArtifactId=kafka-streams-quickstart-producer \\\n"
"    -Dextensions=\"kafka\" \\\n"
"    -DnoExamples \\\n"
"    && mv kafka-streams-quickstart-producer producer\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:96
msgid ""
"This command generates a Maven project, importing the Reactive Messaging and "
"Kafka connector extensions."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:99
msgid ""
"If you already have your Quarkus project configured, you can add the "
"`smallrye-reactive-messaging-kafka` extension to your project by running the "
"following command in your project base directory:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:103
#, no-wrap
msgid ""
"./mvnw quarkus:add-extension "
"-Dextensions=\"quarkus-smallrye-reactive-messaging-kafka\"\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:106 upstream/_guides/kafka-streams.adoc:260
msgid "This will add the following to your `pom.xml`:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:113
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.quarkus</groupId>\n"
"    <artifactId>quarkus-smallrye-reactive-messaging-kafka</artifactId>\n"
"</dependency>\n"
msgstr ""

#. type: Title ===
#: upstream/_guides/kafka-streams.adoc:115
#, no-wrap
msgid "The Temperature Value Producer"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:119
msgid ""
"Create the "
"`producer/src/main/java/org/acme/kafka/streams/producer/generator/ValuesGenerator.java` "
"file, with the following content:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:123
#, no-wrap
msgid "package org.acme.kafka.streams.producer.generator;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:132
#, no-wrap
msgid ""
"import java.math.BigDecimal;\n"
"import java.math.RoundingMode;\n"
"import java.time.Duration;\n"
"import java.time.Instant;\n"
"import java.util.Arrays;\n"
"import java.util.Collections;\n"
"import java.util.List;\n"
"import java.util.Random;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:134
#, no-wrap
msgid "import javax.enterprise.context.ApplicationScoped;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:139
#, no-wrap
msgid ""
"import io.smallrye.mutiny.Multi;\n"
"import io.smallrye.reactive.messaging.kafka.Record;\n"
"import org.eclipse.microprofile.reactive.messaging.Outgoing;\n"
"import org.jboss.logging.Logger;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:148
#, no-wrap
msgid ""
"/**\n"
" * A bean producing random temperature data every second.\n"
" * The values are written to a Kafka topic (temperature-values).\n"
" * Another topic contains the name of weather stations (weather-stations).\n"
" * The Kafka configuration is specified in the application configuration.\n"
" */\n"
"@ApplicationScoped\n"
"public class ValuesGenerator {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:150
#, no-wrap
msgid ""
"    private static final Logger LOG = "
"Logger.getLogger(ValuesGenerator.class);\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:152
#, no-wrap
msgid "    private Random random = new Random();\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:165
#, no-wrap
msgid ""
"    private List<WeatherStation> stations = Collections.unmodifiableList(\n"
"            Arrays.asList(\n"
"                    new WeatherStation(1, \"Hamburg\", 13),\n"
"                    new WeatherStation(2, \"Snowdonia\", 5),\n"
"                    new WeatherStation(3, \"Boston\", 11),\n"
"                    new WeatherStation(4, \"Tokio\", 16),\n"
"                    new WeatherStation(5, \"Cusco\", 12),\n"
"                    new WeatherStation(6, \"Svalbard\", -7),\n"
"                    new WeatherStation(7, \"Porthsmouth\", 11),\n"
"                    new WeatherStation(8, \"Oslo\", 7),\n"
"                    new WeatherStation(9, \"Marrakesh\", 20)\n"
"            ));\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:175
#, no-wrap
msgid ""
"    @Outgoing(\"temperature-values\")                                        "
"// <1>\n"
"    public Multi<Record<Integer, String>> generate() {\n"
"        return Multi.createFrom().ticks().every(Duration.ofMillis(500))    "
"// <2>\n"
"                .onOverflow().drop()\n"
"                .map(tick -> {\n"
"                    WeatherStation station = "
"stations.get(random.nextInt(stations.size()));\n"
"                    double temperature = "
"BigDecimal.valueOf(random.nextGaussian() * 15 + "
"station.averageTemperature)\n"
"                            .setScale(1, RoundingMode.HALF_UP)\n"
"                            .doubleValue();\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:180
#, no-wrap
msgid ""
"                    LOG.infov(\"station: {0}, temperature: {1}\", "
"station.name, temperature);\n"
"                    return Record.of(station.id, Instant.now() + \";\" + "
"temperature);\n"
"                });\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:190
#, no-wrap
msgid ""
"    @Outgoing(\"weather-stations\")                                          "
"// <3>\n"
"    public Multi<Record<Integer, String>> weatherStations() {\n"
"        return Multi.createFrom().items(stations.stream()\n"
"            .map(s -> Record.of(\n"
"                    s.id,\n"
"                    \"{ \\\"id\\\" : \" + s.id +\n"
"                    \", \\\"name\\\" : \\\"\" + s.name + \"\\\" }\"))\n"
"        );\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:192
#, no-wrap
msgid "    private static class WeatherStation {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:196
#, no-wrap
msgid ""
"        int id;\n"
"        String name;\n"
"        int averageTemperature;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:204
#, no-wrap
msgid ""
"        public WeatherStation(int id, String name, int averageTemperature) "
"{\n"
"            this.id = id;\n"
"            this.name = name;\n"
"            this.averageTemperature = averageTemperature;\n"
"        }\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:206
msgid ""
"Instruct Reactive Messaging to dispatch the items from the returned `Multi` "
"to `temperature-values`."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:207
msgid ""
"The method returns a Mutiny _stream_ (`Multi`) emitting a random temperature "
"value every 0.5 seconds."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:208
msgid ""
"Instruct Reactive Messaging to dispatch the items from the returned `Multi` "
"(static list of weather stations) to `weather-stations`."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:210
msgid ""
"The two methods each return a _reactive stream_ whose items are sent to the "
"streams named `temperature-values` and `weather-stations`, respectively."
msgstr ""

#. type: Title ===
#: upstream/_guides/kafka-streams.adoc:211
#, no-wrap
msgid "Topic Configuration"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:215
msgid ""
"The two channels are mapped to Kafka topics using the Quarkus configuration "
"file `application.properties`.  For that, add the following to the file "
"`producer/src/main/resources/application.properties`:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:220
#, no-wrap
msgid ""
"# Configure the Kafka broker location\n"
"kafka.bootstrap.servers=localhost:9092\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:224
#, no-wrap
msgid ""
"mp.messaging.outgoing.temperature-values.connector=smallrye-kafka\n"
"mp.messaging.outgoing.temperature-values.key.serializer=org.apache.kafka.common.serialization.IntegerSerializer\n"
"mp.messaging.outgoing.temperature-values.value.serializer=org.apache.kafka.common.serialization.StringSerializer\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:228
#, no-wrap
msgid ""
"mp.messaging.outgoing.weather-stations.connector=smallrye-kafka\n"
"mp.messaging.outgoing.weather-stations.key.serializer=org.apache.kafka.common.serialization.IntegerSerializer\n"
"mp.messaging.outgoing.weather-stations.value.serializer=org.apache.kafka.common.serialization.StringSerializer\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:232
msgid ""
"This configures the Kafka bootstrap server, the two topics and the "
"corresponding (de-)serializers.  More details about the different "
"configuration options are available on the "
"https://kafka.apache.org/documentation/#producerconfigs[Producer "
"configuration] and "
"https://kafka.apache.org/documentation/#consumerconfigs[Consumer "
"configuration] section from the Kafka documentation."
msgstr ""

#. type: Title ==
#: upstream/_guides/kafka-streams.adoc:233
#, no-wrap
msgid "Creating the Aggregator Maven Project"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:238
msgid ""
"With the producer application in place, it's time to implement the actual "
"aggregator application, which will run the Kafka Streams pipeline.  Create "
"another project like so:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:247
#, no-wrap
msgid ""
"mvn io.quarkus:quarkus-maven-plugin:{quarkus-version}:create \\\n"
"    -DprojectGroupId=org.acme \\\n"
"    -DprojectArtifactId=kafka-streams-quickstart-aggregator \\\n"
"    -Dextensions=\"kafka-streams,resteasy-jackson\" \\\n"
"    -DnoExamples \\\n"
"    && mv kafka-streams-quickstart-aggregator aggregator\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:250
msgid ""
"This creates the `aggregator` project with the Quarkus extension for Kafka "
"Streams and with RESTEasy support for Jackson."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:253
msgid ""
"If you already have your Quarkus project configured, you can add the "
"`kafka-streams` extension to your project by running the following command "
"in your project base directory:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:257
#, no-wrap
msgid "./mvnw quarkus:add-extension -Dextensions=\"kafka-streams\"\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:267
#, no-wrap
msgid ""
"<dependency>\n"
"    <groupId>io.quarkus</groupId>\n"
"    <artifactId>quarkus-kafka-streams</artifactId>\n"
"</dependency>\n"
msgstr ""

#. type: Title ===
#: upstream/_guides/kafka-streams.adoc:269
#, no-wrap
msgid "The Pipeline Implementation"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:273
msgid ""
"Let's begin the implementation of the stream processing application by "
"creating a few value objects for representing temperature measurements, "
"weather stations and for keeping track of aggregated values."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:276
msgid ""
"First, create the file "
"`aggregator/src/main/java/org/acme/kafka/streams/aggregator/model/WeatherStation.java`, "
"representing a weather station, with the following content:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:280 upstream/_guides/kafka-streams.adoc:298 upstream/_guides/kafka-streams.adoc:324 upstream/_guides/kafka-streams.adoc:682
#, no-wrap
msgid "package org.acme.kafka.streams.aggregator.model;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:282 upstream/_guides/kafka-streams.adoc:329 upstream/_guides/kafka-streams.adoc:684
#, no-wrap
msgid "import io.quarkus.runtime.annotations.RegisterForReflection;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:285
#, no-wrap
msgid ""
"@RegisterForReflection // <1>\n"
"public class WeatherStation {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:289
#, no-wrap
msgid ""
"    public int id;\n"
"    public String name;\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:291
msgid ""
"By adding the `@RegisterForReflection` annotation, it is ensured that this "
"type can be instantiated reflectively when running the application in native "
"mode."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:294
msgid ""
"Then the file "
"`aggregator/src/main/java/org/acme/kafka/streams/aggregator/model/TemperatureMeasurement.java`, "
"representing temperature measurements for a given station:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:300 upstream/_guides/kafka-streams.adoc:367
#, no-wrap
msgid "import java.time.Instant;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:302
#, no-wrap
msgid "public class TemperatureMeasurement {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:307
#, no-wrap
msgid ""
"    public int stationId;\n"
"    public String stationName;\n"
"    public Instant timestamp;\n"
"    public double value;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:316
#, no-wrap
msgid ""
"    public TemperatureMeasurement(int stationId, String stationName, Instant "
"timestamp,\n"
"            double value) {\n"
"        this.stationId = stationId;\n"
"        this.stationName = stationName;\n"
"        this.timestamp = timestamp;\n"
"        this.value = value;\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:320
msgid ""
"And finally "
"`aggregator/src/main/java/org/acme/kafka/streams/aggregator/model/Aggregation.java`, "
"which will be used to keep track of the aggregated values while the events "
"are processed in the streaming pipeline:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:327
#, no-wrap
msgid ""
"import java.math.BigDecimal;\n"
"import java.math.RoundingMode;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:332
#, no-wrap
msgid ""
"@RegisterForReflection\n"
"public class Aggregation {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:340
#, no-wrap
msgid ""
"    public int stationId;\n"
"    public String stationName;\n"
"    public double min = Double.MAX_VALUE;\n"
"    public double max = Double.MIN_VALUE;\n"
"    public int count;\n"
"    public double sum;\n"
"    public double avg;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:344
#, no-wrap
msgid ""
"    public Aggregation updateFrom(TemperatureMeasurement measurement) {\n"
"        stationId = measurement.stationId;\n"
"        stationName = measurement.stationName;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:349
#, no-wrap
msgid ""
"        count++;\n"
"        sum += measurement.value;\n"
"        avg = BigDecimal.valueOf(sum / count)\n"
"                .setScale(1, RoundingMode.HALF_UP).doubleValue();\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:352
#, no-wrap
msgid ""
"        min = Math.min(min, measurement.value);\n"
"        max = Math.max(max, measurement.value);\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:356
#, no-wrap
msgid ""
"        return this;\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:361
msgid ""
"Next, let's create the actual streaming query implementation itself in the "
"`aggregator/src/main/java/org/acme/kafka/streams/aggregator/streams/TopologyProducer.java` "
"file.  All we need to do for that is to declare a CDI producer method which "
"returns the Kafka Streams `Topology`; the Quarkus extension will take care "
"of configuring, starting and stopping the actual Kafka Streams engine."
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:365 upstream/_guides/kafka-streams.adoc:598 upstream/_guides/kafka-streams.adoc:645 upstream/_guides/kafka-streams.adoc:869 upstream/_guides/kafka-streams.adoc:923
#, no-wrap
msgid "package org.acme.kafka.streams.aggregator.streams;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:370
#, no-wrap
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.enterprise.inject.Produces;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:383
#, no-wrap
msgid ""
"import org.acme.kafka.streams.aggregator.model.Aggregation;\n"
"import org.acme.kafka.streams.aggregator.model.TemperatureMeasurement;\n"
"import org.acme.kafka.streams.aggregator.model.WeatherStation;\n"
"import org.apache.kafka.common.serialization.Serdes;\n"
"import org.apache.kafka.streams.StreamsBuilder;\n"
"import org.apache.kafka.streams.Topology;\n"
"import org.apache.kafka.streams.kstream.Consumed;\n"
"import org.apache.kafka.streams.kstream.GlobalKTable;\n"
"import org.apache.kafka.streams.kstream.Materialized;\n"
"import org.apache.kafka.streams.kstream.Produced;\n"
"import org.apache.kafka.streams.state.KeyValueBytesStoreSupplier;\n"
"import org.apache.kafka.streams.state.Stores;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:385
#, no-wrap
msgid "import io.quarkus.kafka.client.serialization.ObjectMapperSerde;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:388
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class TopologyProducer {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:390
#, no-wrap
msgid ""
"    static final String WEATHER_STATIONS_STORE = "
"\"weather-stations-store\";\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:394
#, no-wrap
msgid ""
"    private static final String WEATHER_STATIONS_TOPIC = "
"\"weather-stations\";\n"
"    private static final String TEMPERATURE_VALUES_TOPIC = "
"\"temperature-values\";\n"
"    private static final String TEMPERATURES_AGGREGATED_TOPIC = "
"\"temperatures-aggregated\";\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:398
#, no-wrap
msgid ""
"    @Produces\n"
"    public Topology buildTopology() {\n"
"        StreamsBuilder builder = new StreamsBuilder();\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:402
#, no-wrap
msgid ""
"        ObjectMapperSerde<WeatherStation> weatherStationSerde = new "
"ObjectMapperSerde<>(\n"
"                WeatherStation.class);\n"
"        ObjectMapperSerde<Aggregation> aggregationSerde = new "
"ObjectMapperSerde<>(Aggregation.class);\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:405
#, no-wrap
msgid ""
"        KeyValueBytesStoreSupplier storeSupplier = "
"Stores.persistentKeyValueStore(\n"
"                WEATHER_STATIONS_STORE);\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:409
#, no-wrap
msgid ""
"        GlobalKTable<Integer, WeatherStation> stations = "
"builder.globalTable( // <1>\n"
"                WEATHER_STATIONS_TOPIC,\n"
"                Consumed.with(Serdes.Integer(), weatherStationSerde));\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:436
#, no-wrap
msgid ""
"        builder.stream(                                                       "
"// <2>\n"
"                        TEMPERATURE_VALUES_TOPIC,\n"
"                        Consumed.with(Serdes.Integer(), Serdes.String())\n"
"                )\n"
"                .join(                                                        "
"// <3>\n"
"                        stations,\n"
"                        (stationId, timestampAndValue) -> stationId,\n"
"                        (timestampAndValue, station) -> {\n"
"                            String[] parts = "
"timestampAndValue.split(\";\");\n"
"                            return new TemperatureMeasurement(station.id, "
"station.name,\n"
"                                    Instant.parse(parts[0]), "
"Double.valueOf(parts[1]));\n"
"                        }\n"
"                )\n"
"                .groupByKey()                                                 "
"// <4>\n"
"                .aggregate(                                                   "
"// <5>\n"
"                        Aggregation::new,\n"
"                        (stationId, value, aggregation) -> "
"aggregation.updateFrom(value),\n"
"                        Materialized.<Integer, Aggregation> "
"as(storeSupplier)\n"
"                            .withKeySerde(Serdes.Integer())\n"
"                            .withValueSerde(aggregationSerde)\n"
"                )\n"
"                .toStream()\n"
"                .to(                                                          "
"// <6>\n"
"                        TEMPERATURES_AGGREGATED_TOPIC,\n"
"                        Produced.with(Serdes.Integer(), aggregationSerde)\n"
"                );\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:440
#, no-wrap
msgid ""
"        return builder.build();\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:442
msgid ""
"The `weather-stations` table is read into a `GlobalKTable`, representing the "
"current state of each weather station"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:443
msgid ""
"The `temperature-values` topic is read into a `KStream`; whenever a new "
"message arrives to this topic, the pipeline will be processed for this "
"measurement"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:444
msgid ""
"The message from the `temperature-values` topic is joined with the "
"corresponding weather station, using the topic's key (weather station id); "
"the join result contains the data from the measurement and associated "
"weather station message"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:445
msgid "The values are grouped by message key (the weather station id)"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:446
msgid ""
"Within each group, all the measurements of that station are aggregated, by "
"keeping track of minimum and maximum values and calculating the average "
"value of all measurements of that station (see the `Aggregation` type)"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:447
msgid ""
"The results of the pipeline are written out to the `temperatures-aggregated` "
"topic"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:450
msgid ""
"The Kafka Streams extension is configured via the Quarkus configuration file "
"`application.properties`.  Create the file "
"`aggregator/src/main/resources/application.properties` with the following "
"contents:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:456
#, no-wrap
msgid ""
"quarkus.kafka-streams.bootstrap-servers=localhost:9092\n"
"quarkus.kafka-streams.application-server=${hostname}:8080\n"
"quarkus.kafka-streams.topics=weather-stations,temperature-values\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:463
#, no-wrap
msgid ""
"# pass-through options\n"
"kafka-streams.cache.max.bytes.buffering=10240\n"
"kafka-streams.commit.interval.ms=1000\n"
"kafka-streams.metadata.max.age.ms=500\n"
"kafka-streams.auto.offset.reset=earliest\n"
"kafka-streams.metrics.recording.level=DEBUG\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:470
msgid ""
"The options with the `quarkus.kafka-streams` prefix can be changed "
"dynamically at application startup, e.g. via environment variables or system "
"properties.  `bootstrap-servers` and `application-server` are mapped to the "
"Kafka Streams properties `bootstrap.servers` and `application.server`, "
"respectively.  `topics` is specific to Quarkus: the application will wait "
"for all the given topics to exist before launching the Kafka Streams "
"engine.  This is to done to gracefully await the creation of topics that "
"don't yet exist at application startup time."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:473
msgid ""
"All the properties within the `kafka-streams` namespace are passed through "
"as-is to the Kafka Streams engine.  Changing their values requires a rebuild "
"of the application."
msgstr ""

#. type: Title ==
#: upstream/_guides/kafka-streams.adoc:474
#, no-wrap
msgid "Building and Running the Applications"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:477
msgid "We now can build the `producer` and `aggregator` applications:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:482
#, no-wrap
msgid ""
"./mvnw clean package -f producer/pom.xml\n"
"./mvnw clean package -f aggregator/pom.xml\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:487
msgid ""
"Instead of running them directly on the host machine using the Quarkus dev "
"mode, we're going to package them into container images and launch them via "
"Docker Compose.  This is done in order to demonstrate scaling the "
"`aggregator` aggregation to multiple nodes later on."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:490
msgid ""
"The `Dockerfile` created by Quarkus by default needs one adjustment for the "
"`aggregator` application in order to run the Kafka Streams pipeline.  To do "
"so, edit the file `aggregator/src/main/docker/Dockerfile.jvm` and replace "
"the line `FROM fabric8/java-alpine-openjdk8-jre` with `FROM "
"fabric8/java-centos-openjdk8-jdk`."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:492
msgid ""
"Next create a Docker Compose file (`docker-compose.yaml`) for spinning up "
"the two applications as well as Apache Kafka and ZooKeeper like so:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:496
#, no-wrap
msgid "version: '3.5'\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:528
#, no-wrap
msgid ""
"services:\n"
"  zookeeper:\n"
"    image: strimzi/kafka:0.19.0-kafka-2.5.0\n"
"    command: [\n"
"      \"sh\", \"-c\",\n"
"      \"bin/zookeeper-server-start.sh config/zookeeper.properties\"\n"
"    ]\n"
"    ports:\n"
"      - \"2181:2181\"\n"
"    environment:\n"
"      LOG_DIR: /tmp/logs\n"
"    networks:\n"
"      - kafkastreams-network\n"
"  kafka:\n"
"    image: strimzi/kafka:0.19.0-kafka-2.5.0\n"
"    command: [\n"
"      \"sh\", \"-c\",\n"
"      \"bin/kafka-server-start.sh config/server.properties --override "
"listeners=$${KAFKA_LISTENERS} --override "
"advertised.listeners=$${KAFKA_ADVERTISED_LISTENERS} --override "
"zookeeper.connect=$${KAFKA_ZOOKEEPER_CONNECT} --override "
"num.partitions=$${KAFKA_NUM_PARTITIONS}\"\n"
"    ]\n"
"    depends_on:\n"
"      - zookeeper\n"
"    ports:\n"
"      - \"9092:9092\"\n"
"    environment:\n"
"      LOG_DIR: \"/tmp/logs\"\n"
"      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092\n"
"      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092\n"
"      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181\n"
"      KAFKA_NUM_PARTITIONS: 3\n"
"    networks:\n"
"      - kafkastreams-network\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:538
#, no-wrap
msgid ""
"  producer:\n"
"    image: quarkus-quickstarts/kafka-streams-producer:1.0\n"
"    build:\n"
"      context: producer\n"
"      dockerfile: src/main/docker/Dockerfile.${QUARKUS_MODE:-jvm}\n"
"    environment:\n"
"      KAFKA_BOOTSTRAP_SERVERS: kafka:9092\n"
"    networks:\n"
"      - kafkastreams-network\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:548
#, no-wrap
msgid ""
"  aggregator:\n"
"    image: quarkus-quickstarts/kafka-streams-aggregator:1.0\n"
"    build:\n"
"      context: aggregator\n"
"      dockerfile: src/main/docker/Dockerfile.${QUARKUS_MODE:-jvm}\n"
"    environment:\n"
"      QUARKUS_KAFKA_STREAMS_BOOTSTRAP_SERVERS: kafka:9092\n"
"    networks:\n"
"      - kafkastreams-network\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:552
#, no-wrap
msgid ""
"networks:\n"
"  kafkastreams-network:\n"
"    name: ks\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:556
msgid ""
"To launch all the containers, building the `producer` and `aggregator` "
"container images, run `docker-compose up --build`."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:558
msgid ""
"You should see log statements from the `producer` application about messages "
"being sent to the \"temperature-values\" topic."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:561
msgid ""
"Now run an instance of the _debezium/tooling_ image, attaching to the same "
"network all the other containers run in.  This image provides several useful "
"tools such as _kafkacat_ and _httpie_:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:565
#, no-wrap
msgid "docker run --tty --rm -i --network ks debezium/tooling:1.1\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:568
msgid ""
"Within the tooling container, run _kafkacat_ to examine the results of the "
"streaming pipeline:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:572
#, no-wrap
msgid "kafkacat -b kafka:9092 -C -o beginning -q -t temperatures-aggregated\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:577
#, no-wrap
msgid ""
"{\"avg\":34.7,\"count\":4,\"max\":49.4,\"min\":16.8,\"stationId\":9,\"stationName\":\"Marrakesh\",\"sum\":138.8}\n"
"{\"avg\":15.7,\"count\":1,\"max\":15.7,\"min\":15.7,\"stationId\":2,\"stationName\":\"Snowdonia\",\"sum\":15.7}\n"
"{\"avg\":12.8,\"count\":7,\"max\":25.5,\"min\":-13.8,\"stationId\":7,\"stationName\":\"Porthsmouth\",\"sum\":89.7}\n"
"...\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:581
msgid ""
"You should see new values arrive as the producer continues to emit "
"temperature measurements, each value on the outbound topic showing the "
"minimum, maximum and average temperature values of the represented weather "
"station."
msgstr ""

#. type: Title ==
#: upstream/_guides/kafka-streams.adoc:582
#, no-wrap
msgid "Interactive Queries"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:590
msgid ""
"Subscribing to the `temperatures-aggregated` topic is a great way to react "
"to any new temperature values.  It's a bit wasteful though if you're just "
"interested in the latest aggregated value for a given weather station.  This "
"is where Kafka Streams interactive queries shine: they let you directly "
"query the underlying state store of the pipeline for the value associated to "
"a given key.  By exposing a simple REST endpoint which queries the state "
"store, the latest aggregation result can be retrieved without having to "
"subscribe to any Kafka topic."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:592
msgid ""
"Let's begin by creating a new class `InteractiveQueries` in the file "
"`aggregator/src/main/java/org/acme/kafka/streams/aggregator/streams/InteractiveQueries.java`:"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:594
msgid ""
"one more method to the `KafkaStreamsPipeline` class which obtains the "
"current state for a given key:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:601
#, no-wrap
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.inject.Inject;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:608
#, no-wrap
msgid ""
"import org.acme.kafka.streams.aggregator.model.Aggregation;\n"
"import org.acme.kafka.streams.aggregator.model.WeatherStationData;\n"
"import org.apache.kafka.streams.KafkaStreams;\n"
"import org.apache.kafka.streams.errors.InvalidStateStoreException;\n"
"import org.apache.kafka.streams.state.QueryableStoreTypes;\n"
"import org.apache.kafka.streams.state.ReadOnlyKeyValueStore;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:611
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"public class InteractiveQueries {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:614
#, no-wrap
msgid ""
"    @Inject\n"
"    KafkaStreams streams;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:617
#, no-wrap
msgid ""
"    public GetWeatherStationDataResult getWeatherStationData(int id) {\n"
"        Aggregation result = getWeatherStationStore().get(id);\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:625
#, no-wrap
msgid ""
"        if (result != null) {\n"
"            return "
"GetWeatherStationDataResult.found(WeatherStationData.from(result)); // <1>\n"
"        }\n"
"        else {\n"
"            return GetWeatherStationDataResult.notFound();                             "
"// <2>\n"
"        }\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:636
#, no-wrap
msgid ""
"    private ReadOnlyKeyValueStore<Integer, Aggregation> "
"getWeatherStationStore() {\n"
"        while (true) {\n"
"            try {\n"
"                return "
"streams.store(TopologyProducer.WEATHER_STATIONS_STORE, "
"QueryableStoreTypes.keyValueStore());\n"
"            } catch (InvalidStateStoreException e) {\n"
"                // ignore, store not ready yet\n"
"            }\n"
"        }\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:638
msgid "A value for the given station id was found, so that value will be returned"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:639
msgid ""
"No value was found, either because a non-existing station was queried or no "
"measurement exists yet for the given station"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:641
msgid ""
"Also create the method's return type in the file "
"`aggregator/src/main/java/org/acme/kafka/streams/aggregator/streams/GetWeatherStationDataResult.java`:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:648 upstream/_guides/kafka-streams.adoc:872
#, no-wrap
msgid ""
"import java.util.Optional;\n"
"import java.util.OptionalInt;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:650 upstream/_guides/kafka-streams.adoc:874
#, no-wrap
msgid "import org.acme.kafka.streams.aggregator.model.WeatherStationData;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:652 upstream/_guides/kafka-streams.adoc:876
#, no-wrap
msgid "public class GetWeatherStationDataResult {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:655
#, no-wrap
msgid ""
"    private static GetWeatherStationDataResult NOT_FOUND =\n"
"            new GetWeatherStationDataResult(null);\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:657
#, no-wrap
msgid "    private final WeatherStationData result;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:661
#, no-wrap
msgid ""
"    private GetWeatherStationDataResult(WeatherStationData result) {\n"
"        this.result = result;\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:665
#, no-wrap
msgid ""
"    public static GetWeatherStationDataResult found(WeatherStationData data) "
"{\n"
"        return new GetWeatherStationDataResult(data);\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:669 upstream/_guides/kafka-streams.adoc:902
#, no-wrap
msgid ""
"    public static GetWeatherStationDataResult notFound() {\n"
"        return NOT_FOUND;\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:674
#, no-wrap
msgid ""
"    public Optional<WeatherStationData> getResult() {\n"
"        return Optional.ofNullable(result);\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:678
msgid ""
"Also create "
"`aggregator/src/main/java/org/acme/kafka/streams/aggregator/model/WeatherStationData.java`, "
"which represents the actual aggregation result for a weather station:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:687
#, no-wrap
msgid ""
"@RegisterForReflection\n"
"public class WeatherStationData {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:694
#, no-wrap
msgid ""
"    public int stationId;\n"
"    public String stationName;\n"
"    public double min = Double.MAX_VALUE;\n"
"    public double max = Double.MIN_VALUE;\n"
"    public int count;\n"
"    public double avg;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:704
#, no-wrap
msgid ""
"    private WeatherStationData(int stationId, String stationName, double "
"min, double max,\n"
"            int count, double avg) {\n"
"        this.stationId = stationId;\n"
"        this.stationName = stationName;\n"
"        this.min = min;\n"
"        this.max = max;\n"
"        this.count = count;\n"
"        this.avg = avg;\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:715
#, no-wrap
msgid ""
"    public static WeatherStationData from(Aggregation aggregation) {\n"
"        return new WeatherStationData(\n"
"                aggregation.stationId,\n"
"                aggregation.stationName,\n"
"                aggregation.min,\n"
"                aggregation.max,\n"
"                aggregation.count,\n"
"                aggregation.avg);\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:719
msgid ""
"We now can add a simple REST endpoint "
"(`aggregator/src/main/java/org/acme/kafka/streams/aggregator/rest/WeatherStationEndpoint.java`), "
"which invokes `getWeatherStationData()` and returns the data to the client:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:723 upstream/_guides/kafka-streams.adoc:943
#, no-wrap
msgid "package org.acme.kafka.streams.aggregator.rest;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:727 upstream/_guides/kafka-streams.adoc:947
#, no-wrap
msgid ""
"import java.net.URI;\n"
"import java.net.URISyntaxException;\n"
"import java.util.List;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:736
#, no-wrap
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.inject.Inject;\n"
"import javax.ws.rs.GET;\n"
"import javax.ws.rs.Path;\n"
"import javax.ws.rs.PathParam;\n"
"import javax.ws.rs.core.MediaType;\n"
"import javax.ws.rs.core.Response;\n"
"import javax.ws.rs.core.Response.Status;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:739
#, no-wrap
msgid ""
"import "
"org.acme.kafka.streams.aggregator.streams.GetWeatherStationDataResult;\n"
"import org.acme.kafka.streams.aggregator.streams.KafkaStreamsPipeline;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:743 upstream/_guides/kafka-streams.adoc:966
#, no-wrap
msgid ""
"@ApplicationScoped\n"
"@Path(\"/weather-stations\")\n"
"public class WeatherStationEndpoint {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:746 upstream/_guides/kafka-streams.adoc:969
#, no-wrap
msgid ""
"    @Inject\n"
"    InteractiveQueries interactiveQueries;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:751
#, no-wrap
msgid ""
"    @GET\n"
"    @Path(\"/data/{id}\")\n"
"    public Response getWeatherStationData(@PathParam(\"id\") int id) {\n"
"        GetWeatherStationDataResult result = "
"interactiveQueries.getWeatherStationData(id);\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:761
#, no-wrap
msgid ""
"        if (result.getResult().isPresent()) {  // <1>\n"
"            return Response.ok(result.getResult().get()).build();\n"
"        }\n"
"        else {\n"
"            return Response.status(Status.NOT_FOUND.getStatusCode(),\n"
"                    \"No data found for weather station \" + id).build();\n"
"        }\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:763
msgid ""
"Depending on whether a value was obtained, either return that value or a 404 "
"response"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:765
msgid ""
"With this code in place, it's time to rebuild the application and the "
"`aggregator` service in Docker Compose:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:771
#, no-wrap
msgid ""
"./mvnw clean package -f aggregator/pom.xml\n"
"docker-compose stop aggregator\n"
"docker-compose up --build -d\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:776
msgid ""
"This will rebuild the `aggregator` container and restart its service.  Once "
"that's done, you can invoke the service's REST API to obtain the temperature "
"data for one of the existing stations.  To do so, you can use `httpie` in "
"the tooling container launched before:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:780
#, no-wrap
msgid "http aggregator:8080/weather-stations/data/1\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:786
#, no-wrap
msgid ""
"HTTP/1.1 200 OK\n"
"Connection: keep-alive\n"
"Content-Length: 85\n"
"Content-Type: application/json\n"
"Date: Tue, 18 Jun 2019 19:29:16 GMT\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:795
#, no-wrap
msgid ""
"{\n"
"    \"avg\": 12.9,\n"
"    \"count\": 146,\n"
"    \"max\": 41.0,\n"
"    \"min\": -25.6,\n"
"    \"stationId\": 1,\n"
"    \"stationName\": \"Hamburg\"\n"
"}\n"
msgstr ""

#. type: Title ==
#: upstream/_guides/kafka-streams.adoc:797
#, no-wrap
msgid "Scaling Out"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:804
msgid ""
"A very interesting trait of Kafka Streams applications is that they can be "
"scaled out, i.e. the load and state can be distributed amongst multiple "
"application instances running the same pipeline.  Each node will then "
"contain a subset of the aggregation results, but Kafka Streams provides you "
"with "
"https://kafka.apache.org/22/documentation/streams/developer-guide/interactive-queries.html#querying-remote-state-stores-for-the-entire-app[an "
"API] to obtain the information which node is hosting a given key.  The "
"application can then either fetch the data directly from the other instance, "
"or simply point the client to the location of that other node."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:806
msgid ""
"Launching multiple instances of the `aggregator` application will make look "
"the overall architecture like so:"
msgstr ""

#. type: Target for macro image
#: upstream/_guides/kafka-streams.adoc:807
#, no-wrap
msgid "kafka-streams-guide-architecture-distributed.png"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:810
msgid ""
"The `InteractiveQueries` class must be adjusted slightly for this "
"distributed architecture:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:819
#, no-wrap
msgid ""
"public GetWeatherStationDataResult getWeatherStationData(int id) {\n"
"    StreamsMetadata metadata = streams.metadataForKey(                  // "
"<1>\n"
"            TopologyProducer.WEATHER_STATIONS_STORE,\n"
"            id,\n"
"            Serdes.Integer().serializer()\n"
"    );\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:827
#, no-wrap
msgid ""
"    if (metadata == null || metadata == StreamsMetadata.NOT_AVAILABLE) {\n"
"        LOG.warn(\"Found no metadata for key {}\", id);\n"
"        return GetWeatherStationDataResult.notFound();\n"
"    }\n"
"    else if (metadata.host().equals(host)) {                            // "
"<2>\n"
"        LOG.info(\"Found data for key {} locally\", id);\n"
"        Aggregation result = getWeatherStationStore().get(id);\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:845
#, no-wrap
msgid ""
"        if (result != null) {\n"
"            return "
"GetWeatherStationDataResult.found(WeatherStationData.from(result));\n"
"        }\n"
"        else {\n"
"            return GetWeatherStationDataResult.notFound();\n"
"        }\n"
"    }\n"
"    else {                                                              // "
"<3>\n"
"        LOG.info(\n"
"            \"Found data for key {} on remote host {}:{}\",\n"
"            id,\n"
"            metadata.host(),\n"
"            metadata.port()\n"
"        );\n"
"        return GetWeatherStationDataResult.foundRemotely(metadata.host(), "
"metadata.port());\n"
"    }\n"
"}\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:858
#, no-wrap
msgid ""
"public List<PipelineMetadata> getMetaData() {                           // "
"<4>\n"
"    return "
"streams.allMetadataForStore(TopologyProducer.WEATHER_STATIONS_STORE)\n"
"            .stream()\n"
"            .map(m -> new PipelineMetadata(\n"
"                    m.hostInfo().host() + \":\" + m.hostInfo().port(),\n"
"                    m.topicPartitions()\n"
"                        .stream()\n"
"                        .map(TopicPartition::toString)\n"
"                        .collect(Collectors.toSet()))\n"
"            )\n"
"            .collect(Collectors.toList());\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:860
msgid "The streams metadata for the given weather station id is obtained"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:861
msgid ""
"The given key (weather station id) is maintained by the local application "
"node, i.e. it can answer the query itself"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:862
msgid ""
"The given key is maintained by another application node; in this case the "
"information about that node (host and port) will be returned"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:863
msgid ""
"The `getMetaData()` method is added to provide callers with a list of all "
"the nodes in the application cluster."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:865
msgid "The `GetWeatherStationDataResult` type must be adjusted accordingly:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:879
#, no-wrap
msgid ""
"    private static GetWeatherStationDataResult NOT_FOUND =\n"
"            new GetWeatherStationDataResult(null, null, null);\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:883
#, no-wrap
msgid ""
"    private final WeatherStationData result;\n"
"    private final String host;\n"
"    private final Integer port;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:890
#, no-wrap
msgid ""
"    private GetWeatherStationDataResult(WeatherStationData result, String "
"host,\n"
"            Integer port) {\n"
"        this.result = result;\n"
"        this.host = host;\n"
"        this.port = port;\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:894
#, no-wrap
msgid ""
"    public static GetWeatherStationDataResult found(WeatherStationData data) "
"{\n"
"        return new GetWeatherStationDataResult(data, null, null);\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:898
#, no-wrap
msgid ""
"    public static GetWeatherStationDataResult foundRemotely(String host, int "
"port) {\n"
"        return new GetWeatherStationDataResult(null, host, port);\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:906
#, no-wrap
msgid ""
"    public Optional<WeatherStationData> getResult() {\n"
"        return Optional.ofNullable(result);\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:910
#, no-wrap
msgid ""
"    public Optional<String> getHost() {\n"
"        return Optional.ofNullable(host);\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:915
#, no-wrap
msgid ""
"    public OptionalInt getPort() {\n"
"        return port != null ? OptionalInt.of(port) : OptionalInt.empty();\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:919
msgid ""
"Also the return type for `getMetaData()` must be defined "
"(`aggregator/src/main/java/org/acme/kafka/streams/aggregator/streams/PipelineMetadata.java`):"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:925
#, no-wrap
msgid "import java.util.Set;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:927
#, no-wrap
msgid "public class PipelineMetadata {\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:930
#, no-wrap
msgid ""
"    public String host;\n"
"    public Set<String> partitions;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:936
#, no-wrap
msgid ""
"    public PipelineMetadata(String host, Set<String> partitions) {\n"
"        this.host = host;\n"
"        this.partitions = partitions;\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:939
msgid "Lastly, the REST endpoint class must be updated:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:958
#, no-wrap
msgid ""
"import javax.enterprise.context.ApplicationScoped;\n"
"import javax.inject.Inject;\n"
"import javax.ws.rs.Consumes;\n"
"import javax.ws.rs.GET;\n"
"import javax.ws.rs.Path;\n"
"import javax.ws.rs.PathParam;\n"
"import javax.ws.rs.Produces;\n"
"import javax.ws.rs.core.MediaType;\n"
"import javax.ws.rs.core.Response;\n"
"import javax.ws.rs.core.Response.Status;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:962
#, no-wrap
msgid ""
"import "
"org.acme.kafka.streams.aggregator.streams.GetWeatherStationDataResult;\n"
"import org.acme.kafka.streams.aggregator.streams.KafkaStreamsPipeline;\n"
"import org.acme.kafka.streams.aggregator.streams.PipelineMetadata;\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:976
#, no-wrap
msgid ""
"    @GET\n"
"    @Path(\"/data/{id}\")\n"
"    @Consumes(MediaType.APPLICATION_JSON)\n"
"    @Produces(MediaType.APPLICATION_JSON)\n"
"    public Response getWeatherStationData(@PathParam(\"id\") int id) {\n"
"        GetWeatherStationDataResult result = "
"interactiveQueries.getWeatherStationData(id);\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:990
#, no-wrap
msgid ""
"        if (result.getResult().isPresent()) {                     // <1>\n"
"            return Response.ok(result.getResult().get()).build();\n"
"        }\n"
"        else if (result.getHost().isPresent()) {                  // <2>\n"
"            URI otherUri = getOtherUri(result.getHost().get(), "
"result.getPort().getAsInt(),\n"
"                    id);\n"
"            return Response.seeOther(otherUri).build();\n"
"        }\n"
"        else {                                                    // <3>\n"
"            return Response.status(Status.NOT_FOUND.getStatusCode(),\n"
"                    \"No data found for weather station \" + id).build();\n"
"        }\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:997
#, no-wrap
msgid ""
"    @GET\n"
"    @Path(\"/meta-data\")\n"
"    @Produces(MediaType.APPLICATION_JSON)\n"
"    public List<PipelineMetadata> getMetaData() {                 // <4>\n"
"        return interactiveQueries.getMetaData();\n"
"    }\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1007
#, no-wrap
msgid ""
"    private URI getOtherUri(String host, int port, int id) {\n"
"        try {\n"
"            return new URI(\"http://\" + host + \":\" + port + "
"\"/weather-stations/data/\" + id);\n"
"        }\n"
"        catch (URISyntaxException e) {\n"
"            throw new RuntimeException(e);\n"
"        }\n"
"    }\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1009
msgid "The data was found locally, so return it"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1010
msgid ""
"The data is maintained by another node, so reply with a redirect (HTTP "
"status code 303) if the data for the given key is stored on one of the other "
"nodes."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1011
msgid "No data was found for the given weather station id"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1012
msgid "Exposes information about all the hosts forming the application cluster"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1015
msgid ""
"Now stop the `aggregator` service again and rebuild it.  Then let's spin up "
"three instances of it:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1021
#, no-wrap
msgid ""
"./mvnw clean package -f aggregator/pom.xml\n"
"docker-compose stop aggregator\n"
"docker-compose up --build -d --scale aggregator=3\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1026
msgid ""
"When invoking the REST API on any of the three instances, it might either be "
"that the aggregation for the requested weather station id is stored locally "
"on the node receiving the query, or it could be stored on one of the other "
"two nodes."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1030
msgid ""
"As the load balancer of Docker Compose will distribute requests to the "
"`aggregator` service in a round-robin fashion, we'll invoke the actual nodes "
"directly.  The application exposes information about all the host names via "
"REST:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1034
#, no-wrap
msgid "http aggregator:8080/weather-stations/meta-data\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1040
#, no-wrap
msgid ""
"HTTP/1.1 200 OK\n"
"Connection: keep-alive\n"
"Content-Length: 202\n"
"Content-Type: application/json\n"
"Date: Tue, 18 Jun 2019 20:00:23 GMT\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1061
#, no-wrap
msgid ""
"[\n"
"    {\n"
"        \"host\": \"2af13fe516a9:8080\",\n"
"        \"partitions\": [\n"
"            \"temperature-values-2\"\n"
"        ]\n"
"    },\n"
"    {\n"
"        \"host\": \"32cc8309611b:8080\",\n"
"        \"partitions\": [\n"
"            \"temperature-values-1\"\n"
"        ]\n"
"    },\n"
"    {\n"
"        \"host\": \"1eb39af8d587:8080\",\n"
"        \"partitions\": [\n"
"            \"temperature-values-0\"\n"
"        ]\n"
"    }\n"
"]\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1065
msgid ""
"Retrieve the data from one of the three hosts shown in the response (your "
"actual host names will differ):"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1069
#, no-wrap
msgid "http 2af13fe516a9:8080/weather-stations/data/1\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1072
msgid "If that node holds the data for key \"1\", you'll get a response like this:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1080
#, no-wrap
msgid ""
"HTTP/1.1 200 OK\n"
"Connection: keep-alive\n"
"Content-Length: 74\n"
"Content-Type: application/json\n"
"Date: Tue, 11 Jun 2019 19:16:31 GMT\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1089
#, no-wrap
msgid ""
"{\n"
"  \"avg\": 11.9,\n"
"  \"count\": 259,\n"
"  \"max\": 50.0,\n"
"  \"min\": -30.1,\n"
"  \"stationId\": 1,\n"
"  \"stationName\": \"Hamburg\"\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1092
msgid "Otherwise, the service will send a redirect:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1100
#, no-wrap
msgid ""
"HTTP/1.1 303 See Other\n"
"Connection: keep-alive\n"
"Content-Length: 0\n"
"Date: Tue, 18 Jun 2019 20:01:03 GMT\n"
"Location: http://1eb39af8d587:8080/weather-stations/data/1\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1103
msgid ""
"You can also have _httpie_ automatically follow the redirect by passing the "
"`--follow option`:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1107
#, no-wrap
msgid "http --follow 2af13fe516a9:8080/weather-stations/data/1\n"
msgstr ""

#. type: Title ==
#: upstream/_guides/kafka-streams.adoc:1109
#, no-wrap
msgid "Running Natively"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1113
msgid ""
"The Quarkus extension for Kafka Streams enables the execution of stream "
"processing applications natively via GraalVM without further configuration."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1116
msgid ""
"To run both the `producer` and `aggregator` applications in native mode, the "
"Maven builds can be executed using the `native` profile:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1121
#, no-wrap
msgid ""
"./mvnw clean package -f producer/pom.xml -Pnative "
"-Dnative-image.container-runtime=docker\n"
"./mvnw clean package -f aggregator/pom.xml -Pnative "
"-Dnative-image.container-runtime=docker\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1124
msgid ""
"Now create an environment variable named `QUARKUS_MODE` and with value set "
"to \"native\":"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1128
#, no-wrap
msgid "export QUARKUS_MODE=native\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1133
msgid ""
"This is used by the Docker Compose file to use the correct `Dockerfile` when "
"building the `producer` and `aggregator` images.  The Kafka Streams "
"application can work with less than 50 MB RSS in native mode.  To do so, add "
"the `Xmx` option to the program invocation in "
"`aggregator/src/main/docker/Dockerfile.native`:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1137
#, no-wrap
msgid "CMD [\"./application\", \"-Dquarkus.http.host=0.0.0.0\", \"-Xmx32m\"]\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1141
msgid ""
"Now start Docker Compose as described above (don't forget to rebuild the "
"container images)."
msgstr ""

#. type: Title ==
#: upstream/_guides/kafka-streams.adoc:1142
#, no-wrap
msgid "Kafka Streams Health Checks"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1145
msgid ""
"If you are using the `quarkus-smallrye-health` extension, "
"`quarkus-kafka-streams` will automatically add:"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1147
msgid ""
"a readiness health check to validate that all topics declared in the "
"`quarkus.kafka-streams.topics` property are created,"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1148
msgid "a liveness health check based on the Kafka Streams state."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1150
msgid ""
"So when you access the `/health` endpoint of your application you will have "
"information about the state of the Kafka Streams and the available and/or "
"missing topics."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1152
msgid "This is an example of when the status is `DOWN`:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1155
#, no-wrap
msgid "curl -i http://aggregator:8080/health\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1159
#, no-wrap
msgid ""
"HTTP/1.1 503 Service Unavailable\n"
"content-type: application/json; charset=UTF-8\n"
"content-length: 454\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1180
#, no-wrap
msgid ""
"{\n"
"    \"status\": \"DOWN\",\n"
"    \"checks\": [\n"
"        {\n"
"            \"name\": \"Kafka Streams state health check\",  <1>\n"
"            \"status\": \"DOWN\",\n"
"            \"data\": {\n"
"                \"state\": \"CREATED\"\n"
"            }\n"
"        },\n"
"        {\n"
"            \"name\": \"Kafka Streams topics health check\",  <2>\n"
"            \"status\": \"DOWN\",\n"
"            \"data\": {\n"
"                \"available_topics\": "
"\"weather-stations,temperature-values\",\n"
"                \"missing_topics\": \"hygrometry-values\"\n"
"            }\n"
"        }\n"
"    ]\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1182
msgid "Liveness health check. Also available at `/health/live` endpoint."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1183
msgid "Readiness health check. Also available at `/health/ready` endpoint."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1185
msgid ""
"So as you can see, the status is `DOWN` as soon as one of the "
"`quarkus.kafka-streams.topics` is missing or the Kafka Streams `state` is "
"not `RUNNING`."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1188
msgid ""
"If no topics are available, the `available_topics` key will not be present "
"in the `data` field of the `Kafka Streams topics health check`.  As well as "
"if no topics are missing, the `missing_topics` key will not be present in "
"the `data` field of the `Kafka Streams topics health check`."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1190
msgid ""
"You can of course disable the health check of the `quarkus-kafka-streams` "
"extension by setting the `quarkus.kafka-streams.health.enabled` property to "
"`false` in your `application.properties`."
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1192
msgid ""
"Obviously you can create your liveness and readiness probes based on the "
"respective endpoints `/health/live` and `/health/ready`."
msgstr ""

#. type: Title ===
#: upstream/_guides/kafka-streams.adoc:1193
#, no-wrap
msgid "Liveness health check"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1196
msgid "Here is an example of the liveness check:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1200
#, no-wrap
msgid "curl -i http://aggregator:8080/health/live\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1204
#, no-wrap
msgid ""
"HTTP/1.1 503 Service Unavailable\n"
"content-type: application/json; charset=UTF-8\n"
"content-length: 225\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1217
#, no-wrap
msgid ""
"{\n"
"    \"status\": \"DOWN\",\n"
"    \"checks\": [\n"
"        {\n"
"            \"name\": \"Kafka Streams state health check\",\n"
"            \"status\": \"DOWN\",\n"
"            \"data\": {\n"
"                \"state\": \"CREATED\"\n"
"            }\n"
"        }\n"
"    ]\n"
"}\n"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1219
msgid "The `state` is coming from the `KafkaStreams.State` enum."
msgstr ""

#. type: Title ===
#: upstream/_guides/kafka-streams.adoc:1220
#, no-wrap
msgid "Readiness health check"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1223
msgid "Here is an example of the readiness check:"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1227
#, no-wrap
msgid "curl -i http://aggregator:8080/health/ready\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1231
#, no-wrap
msgid ""
"HTTP/1.1 503 Service Unavailable\n"
"content-type: application/json; charset=UTF-8\n"
"content-length: 265\n"
msgstr ""

#. type: delimited block -
#: upstream/_guides/kafka-streams.adoc:1244
#, no-wrap
msgid ""
"{\n"
"    \"status\": \"DOWN\",\n"
"    \"checks\": [\n"
"        {\n"
"            \"name\": \"Kafka Streams topics health check\",\n"
"            \"status\": \"DOWN\",\n"
"            \"data\": {\n"
"                \"missing_topics\": "
"\"weather-stations,temperature-values\"\n"
"            }\n"
"        }\n"
"    ]\n"
"}\n"
msgstr ""

#. type: Title ==
#: upstream/_guides/kafka-streams.adoc:1246
#, no-wrap
msgid "Going Further"
msgstr ""

#. type: Plain text
#: upstream/_guides/kafka-streams.adoc:1252
msgid ""
"This guide has shown how you can build stream processing applications using "
"Quarkus and the Kafka Streams APIs, both in JVM and native modes.  For "
"running your KStreams application in production, you could also add health "
"checks and metrics for the data pipeline.  Refer to the Quarkus guides on "
"link:micrometer[Micrometer], link:microprofile-metrics[MicroProfile "
"Metrics], and link:microprofile-health[health checks] to learn more."
msgstr ""

#. type: Title ==
#: upstream/_guides/kafka-streams.adoc:1253
#, no-wrap
msgid "Configuration Reference"
msgstr ""
