msgid ""
msgstr ""
"Language: ja_JP\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"X-Generator: jekyll-l10n\n"

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "Agentic AI with Quarkus - part 1"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "Although there is no universally agreed definition of an AI agent, several emerging patterns demonstrate how to coordinate and combine the capabilities of multiple AI services to create AI-infused applications that can accomplish more complex tasks."
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "According to a https://www.anthropic.com/research/building-effective-agents[recent article published by Antropic researchers], these _Agentic System architectures_ can be grouped into two main categories:"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "**workflows**: LLMs and tools are orchestrated through predefined code paths,"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "**agents**: LLMs dynamically direct their processes and tool usage, maintaining control over how they execute tasks."
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "The goal of this series of articles is to discuss the most common workflow and agentic AI patterns and architectures, with the practical aid of https://github.com/mariofusco/quarkus-agentic-ai[this project] that demonstrates for each of them an example of how they can be implemented through Quarkus and its LangChain4j integration. Of course, a real-world application may use and combine these patterns in multiple ways to implement a complex behavior."
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "This first article focuses on the _workflow_ patterns. A second article will cover the _agent_ patterns."
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "All the demos in that project run the LLMs inference locally through an https://ollama.com/[ollama] server. In particular the demos in the workflow section use a llama3.2 model, while the ones relative to the pure agents one employ qwen2.5 since this last model empirically demonstrated of working better when multiple tool callings are required."
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "Workflow patterns"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid ""
"AI workflows are patterns in which different LLM-based services (_AI services_ in the Quarkus vocabulary) are coordinated **programmatically** in a predetermined manner.\n"
"This article introduces three base patterns, namely:"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "xref:#prompt-chaining[the prompt chaining pattern]"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "xref:#parallelization[the parallelization pattern]"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "xref:#routing[the routing pattern]"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "Prompt chaining"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "Prompt chaining is, without a doubt, the simplest yet powerful and effective technique in agentic AI workflows. In this technique, the output of one prompt (the response from an LLM) becomes the input of the next, enabling complex, multi-step reasoning or task execution. It is ideal for situations with a straightforward way to decompose a complex task into smaller and better-delimited steps, thus reducing the possibility of hallucinations or other LLMs misbehaving."
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "Understanding that each coordinated call to LLM may rely on different models and system messages is essential. Thus, each step can be implemented using a more specialized model and system message."
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "A typical use case for applying this technique is content creation, like advertising or novel writing. For instance, this https://github.com/mariofusco/quarkus-agentic-ai/blob/main/src/main/java/org/agenticai/promptchaining[first example] leverages this pattern to implement a creative writing and editing workflow, where the https://github.com/mariofusco/quarkus-agentic-ai/blob/main/src/main/java/org/agenticai/promptchaining/CreativeWriter.java[first AI service] is the following:"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "It generates a story draft on a topic provided by the user. In contrast, two more services, implemented very similarly to this one, subsequently modify the outcome of the first one. In particular, a https://github.com/mariofusco/quarkus-agentic-ai/blob/main/src/main/java/org/agenticai/promptchaining/StyleEditor.java[second service] rewrites the draft to make it more coherent with a determined style, while a https://github.com/mariofusco/quarkus-agentic-ai/blob/main/src/main/java/org/agenticai/promptchaining/AudienceEditor.java[third one] executes a final edit to make it a good fit for the required audience."
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "It is also worth to be noted that all these three AI services are intended to be used through one-shot calls in a completely stateless way, so they are configured to not have any https://docs.langchain4j.dev/tutorials/chat-memory/[chat memory]. Regardless of this configuration, each AI service has its own chat memory, confined to the single service, and this is why it is necessary to explicitly pass to each of them the output produced by the former LLM in the chain."
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "Prompt chaining pattern"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "In this case, it is pretty straightforward to expose this service through a https://github.com/mariofusco/quarkus-agentic-ai/blob/main/src/main/java/org/agenticai/promptchaining/WriterResource.java[HTTP endpoint] that invokes these AI services one after the other, making the editors rewrite or refine the content produced by the first creative writer:"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "The HTTP endpoint allows us to define a topic, style, and audience of the novel to be produced; so, for example, running the project locally, it would be possible to obtain a drama about dogs having kids as the target audience by calling this URL:"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "As an example, it generates a result like https://github.com/mariofusco/quarkus-agentic-ai/blob/main/text/dogs-novel.txt[this]. Since this project integrates the observability capabilities provided by Quarkus out-of-the-box, it is also possible to look at the tracing of the flow of invocations performed to fulfill this request, which, of course, puts in evidence of the sequential nature of this pattern."
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "Tracing sequential execution of the prompt chaining pattern"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "Parallelization"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "This second pattern also orchestrates multiple calls to LLMs. However, unlike the prompt chaining pattern, the calls are independent and do not require the output of one call to be used as the input of another. In these situations, those calls can be performed in parallel, followed by an aggregator that combines their outcomes."
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "To demonstrate how this works, let's consider this https://github.com/mariofusco/quarkus-agentic-ai/blob/main/src/main/java/org/agenticai/parallelization[second example]. This code recommends a plan for a lovely evening with a specific mood, combining a movie and a meal that matches that mood. The https://github.com/mariofusco/quarkus-agentic-ai/blob/main/src/main/java/org/agenticai/parallelization/EveningPlannerResource.java[HTTP endpoint] implements this goal by invoking two different AI services **in parallel** and then combining their outcome, putting together the three different suggestions of the two different LLM-based experts."
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "The https://github.com/mariofusco/quarkus-agentic-ai/blob/main/src/main/java/org/agenticai/parallelization/MovieExpert.java[first LLM] is an AI service asked to provide three titles of movies matching the given mood."
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "The https://github.com/mariofusco/quarkus-agentic-ai/blob/main/src/main/java/org/agenticai/parallelization/FoodExpert.java[second one], with a very similar implementation is asked to provide three meals. When these LLM calls are complete, the results (3 lists of 3 items each) are aggregated to create a list of 3 fantastic evening plans with a suggested movie and meal each."
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "The parallelization pattern"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "For instance asking that endpoint to provide evening plans for a romantic mood:"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "The outcome is something like:"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid ""
"[\n"
"  EveningPlan[movie=1. The Notebook, meal=1. Candlelit Chicken Piccata],\n"
"  EveningPlan[movie=2. La La Land, meal=2. Rose Petal Risotto],\n"
"  EveningPlan[movie=3. Crazy, Stupid, Love., meal=3. Sunset Seared Scallops]\n"
"]"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "In this case, the tracing of the flow of invocations performed to fulfill this request shows, as expected, that the two LLM invocations are performed in parallel."
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "Tracing parallel LLMs invocation"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "Routing"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "Another common situation is the need to direct tasks requiring specific handling to specialized models, tools, or processes based on determined criteria. In these cases, the routing workflow allows the dynamic allocation of tasks to the most suitable AI service."
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "https://github.com/mariofusco/quarkus-agentic-ai/blob/main/src/main/java/org/agenticai/routing[This example] shows how this pattern can be applied in a simple scenario where a user asks a question that has to be redirected to a https://github.com/mariofusco/quarkus-agentic-ai/blob/main/src/main/java/org/agenticai/routing/LegalExpert.java[legal], https://github.com/mariofusco/quarkus-agentic-ai/blob/main/src/main/java/org/agenticai/routing/MedicalExpert.java[medical] or https://github.com/mariofusco/quarkus-agentic-ai/blob/main/src/main/java/org/agenticai/routing/TechnicalExpert.java[technical] expert to be answered most accurately, where any of these experts are an AI service implemented for instance as follows:"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "The categorization of the user's request is performed by https://github.com/mariofusco/quarkus-agentic-ai/blob/main/src/main/java/org/agenticai/routing/CategoryRouter.java[another LLM service]"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "that returns one of the possible categories of the user's request, encoded in this enumeration:"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "Thus, the https://github.com/mariofusco/quarkus-agentic-ai/blob/main/src/main/java/org/agenticai/routing/RouterService.java[router service] can send the question to the right expert."
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "Routing pattern"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "In this way, when the user calls the https://github.com/mariofusco/quarkus-agentic-ai/blob/main/src/main/java/org/agenticai/routing/ExpertAssistanceResource.java[HTTP endpoint], exposing this service writing something like: \"I broke my leg what should I do\":"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "The first LLM categorizes this request as a medical one, and the router forwards it to the medical expert LLM, thus generating a result like https://github.com/mariofusco/quarkus-agentic-ai/blob/main/text/expert-response.txt[this]."
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "Conclusion"
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid ""
"This article demonstrated how you can implement _workflow patterns_ with Quarkus Langchain4J.\n"
"Quarkus Langchain4J provides a powerful and flexible way to implement these patterns, allowing you to orchestrate multiple AI services in a way that is both efficient and easy to understand."
msgstr ""

#: _posts/2025-02-18-agentic-ai-with-quarkus.adoc
msgid "The next article will cover the _agent patterns_. So, stay tuned!"
msgstr ""
