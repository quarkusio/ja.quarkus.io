msgid ""
msgstr ""
"Language: ja_JP\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"X-Generator: jekyll-l10n\n"

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "When Quarkus meets LangChain4j"
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Learn about the new quarkus-langchain4j extension to integrate LLMs in Quarkus applications."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Large language models (LLMs) are reshaping the world of software, altering the way we interact with users and develop business logic."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Popularized by https://openai.com/[OpenAI]'s https://chat.openai.com/[ChatGPT], LLMs are now available in many flavors and sizes. The https://huggingface.co/models[Hugging-Face] platform references hundreds of them, and major tech companies like Facebook, Google, Microsoft, Amazon and IBM are also providing their own models."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "LLMs are not a new concept. They have been around for a while, but they were not as powerful or as accessible they became when OpenAI made ChatGPT API's publically available. Since then the Quarkus team have been thinking about what it would mean to integrate LLMs in the Quarkus ecosystem. The talk https://www.youtube.com/watch?app=desktop&v=BD1MSLbs9KE[Java Meets AI] from Lize Raes at Devoxx 2023 has been a great source of inspiration."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Since, the Quarkus team, in collaboration with Dmytro Liubarskyi and the LangChain4j team, has been working on an extension to integrate LLMs in Quarkus applications. This extension is based on the https://github.com/langchain4j[LangChain4j library], which provides a common API to interact with LLMs. The LangChain4j project is a Java re-implementation of the famous https://www.langchain.com/[langchain] library."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "In this blog post, we will see how to use the just released https://docs.quarkiverse.io/quarkus-langchain4j/dev/index.html[quarkus-langchain4j] 0.1 extension to integrate LLMs in Quarkus applications. This extension is an exploration to understand how LLMs can be used in Quarkus applications."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "We recorded a live Fireside chat on this extension. You can watch it here, the blog continues <<overview,below>>."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Overview"
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "First, let's have a look at the big picture. When integrating an LLM into a Quarkus application, you need to describe what you want the AI to do. Unlike traditional code, you are going to explain the behavior of the AI using natural language. Of course, there are a few techniques to tame the AI, but we will explore that later."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Strictly relying on the LLM's knowledge might not be enough. Thus, the Quarkus LangChain4j extension provides two mechanisms to extend AI knowledge:"
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "_Tools_ - a tool lets the LLM execute actions in your application. For instance, you can use a tool to send an email, call a REST endpoint, or execute a database query. The LLM decides when to use the tool, the method parameters, and what to do with the result."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "_Document stores_ - LLMs are not good at remembering things. In addition, their context has a size limit. Thus, the extension provides a way to store and retrieve information from document stores. Before calling the LLM, the extension can ask for relevant documents in a document store and attach them to the context. The LLM can then use this data to make a decision. For instance, you can load spreadsheet data, reports, or data from a database."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "The following diagram illustrates the interactions between the LLM, the tools, and the document stores:"
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Show me some code!"
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Alright, enough \"bla bla\", let's see some code! We are going to use Open AI GPT-3.5 (be careful that it's not the state-of-the-art model, but it's good enough for this demo), give it some product reviews, and ask the LLM to classify them between positive and negative reviews. The full code is available in the https://github.com/quarkiverse/quarkus-langchain4j/tree/main/samples/review-triage[quarkus-langchain4j repository]."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "First, we need the `quarkus-langchain4j-openai` extension:"
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Once we have the extension, it's time to tell the LLM what we want to do. The Quarkus LangChain4J extension provides a declarative way to describe LLM interactions. The idea is the same as the Quarkus REST client. We model the interaction using an interface annotated with `@RegisterAiService`:"
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "The rest of the application would be able to use the LLM by injecting the `TriageService` interface and calling the methods."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Speaking about methods, that's where the magic happens. You will describe what you want the LLM to do using natural language. First, you start with `@SystemMessage` to define the role and scope. Then, you can use `@UserMessage` to describe the task."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Voil√†! That's all you need to do to describe the interaction with the LLM. The instructions follow a set of principles to shape the LLM response. Learn more about these techniques in https://docs.quarkiverse.io/quarkus-langchain4j/dev/prompt-engineering.html[the dedicated prompt engineering page]."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Now, to call the LLM from the application code, just inject the `TriageService` and call the `triage` method:"
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "That's it! The LLM is now integrated into the application. The `TriageService` interface is used as an ambassador to call the LLM. This declarative approach has many advantages:"
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Testability - you can easily mock the LLM by providing a fake implementation of the interface."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Observability - you can use the Quarkus metrics annotation to monitor the LLM methods."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Resilience - you can use the Quarkus fault-tolerance annotations to handle failures, timeouts, and other transient issues."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Tools and Document loader"
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "The previous example is a bit simplistic. In the real world, you will need to extend the LLM knowledge with tools and document stores. The `@RegisterAiService` annotation lets you define the tools and document stores to use."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Tools"
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Tools are methods that the LLM can invoke."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "To declare a tool, just use the `@Tool` annotation on a _bean_ method:"
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "In this example, we are using the Panache repository pattern to access the database. We have a specific method annotated with `@Tool` to retrieve the customer name. When the LLM needs to get the customer name, it instructs Quarkus to call this method and receives the result."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Obviously, it's not a good idea to expose every operation to the LLM. So, in addition to `@Tool`, you need to list the set of tools you allow the LLM to invoke in the `@RegisterAiService` annotation:"
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "The `chatMemoryProviderSupplier` configuration may raise questions. When using tools, a sequence of messages unfolds behind the scenes. It becomes necessary to configure the AI service's memory to adeptly track these interactions. The `chatMemoryProviderSupplier` allows configuring how the memory is handled. The value `BeanChatMemoryProviderSupplier.class` instructs Quarkus to look for a `ChatMemoryProvider` bean, like the following:"
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "At the moment, only the OpenAI models support tools."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Document stores"
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Document stores are a way to extend the LLM knowledge with your own data. This approach - called Retrieval Augmented Generation (_RAG_) - requires two processes:"
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "The ingestion process"
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "you ingest documents into a document store. The documents are not stored as-is, but an embedding is computed. This embedding is a vector representation of the document."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "The RAG process"
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "in the Quarkus application, you need to declare the document store and the embedding to use. Thus, before calling the LLM, it retrieves the relevant documents from the store (that's where the vector representation is useful) and attaches them to the LLM context (which essentially means adding the retrieved information from the document to the user message)."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "The Quarkus LangChain4j extension provides facilities for both processes."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "The following code shows how to ingest a document into a Redis document store:"
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Then, generally, in another application, you can use the populated document store to extend the LLM knowledge. First, create a bean implementing the `Retriever<TextSegment>` interface:"
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Then, add the document store and the retriever to the `@RegisterAiService` annotation:"
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "`RegisterAiService.BeanRetrieverSupplier.class` is a special value looking for the `Retriever` bean in the Quarkus application."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "Final notes"
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "This post presented the Quarkus LangChain4j extension. This is the first version of the extension, and we continue exploring and experimenting with approaches to integrate LLMs into Quarkus applications. We are looking for feedback and ideas to improve these integrations. We are working on removing some rough angles, and exploring other ways to integrate LLMs and to bring developer joy when integrating with LLMs."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "This extension would not have been possible without the fantastic work from Dmytro Liubarskyi on the LangChain4j library. Our collaboration has allowed us to provide a Quarkus-friendly approach to integrate the library (including native compilation support) and shape a new way to integrate LLMs in Quarkus applications. The current design was tailored to enable Quarkus applications to use LLM easily. You can basically hook up any of your _beans_ as tools or ingest data into a store. In addition, any of your bean can now interact with an LLM."
msgstr ""

#: _posts/2023-11-16-quarkus-meets-langchain4j.adoc
msgid "We are looking forward to continuing this collaboration and to see what you will build with this extension."
msgstr ""
