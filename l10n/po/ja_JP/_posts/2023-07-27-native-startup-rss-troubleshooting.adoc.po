# SOME DESCRIPTIVE TITLE
# Copyright (C) YEAR Free Software Foundation, Inc.
# This file is distributed under the same license as the PACKAGE package.
# FIRST AUTHOR <EMAIL@ADDRESS>, YEAR.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: PACKAGE VERSION\n"
"POT-Creation-Date: 2023-07-30 08:14+0000\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"Language-Team: LANGUAGE <LL@li.org>\n"
"Language: ja_JP\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"

#. type: YAML Front Matter: author
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:1
#, no-wrap
msgid "galderz"
msgstr "galderz"

#. type: YAML Front Matter: date
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:1
#, no-wrap
msgid "2023-07-27"
msgstr ""

#. type: YAML Front Matter: layout
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:1
#, no-wrap
msgid "post"
msgstr "post"

#. type: YAML Front Matter: synopsis
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:1
#, no-wrap
msgid "Use Linux native tooling and JFR to understand Quarkus Native startup RSS consumption"
msgstr ""

#. type: YAML Front Matter: tags
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:1
#, no-wrap
msgid "native rss jfr"
msgstr ""

#. type: YAML Front Matter: title
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:1
#, no-wrap
msgid "Analysing Quarkus Native startup RSS consumption"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:18
msgid "During the development of Quarkus 2.13, we discovered that there was a startup degradation in native mode.  One of the key aspects of this degradation was that RSS consumption on start up had gone up by about 10-15% compared to Quarkus 2.7.  In this blog post you will learn how the Quarkus native RSS consumption debugging techniques described in https://quarkus.io/guides/native-reference#rss[the Quarkus native reference guide] were used to diagnose this issue.  You will also learn about recent updates in GraalVM that make doing this kind of analysis more convenient."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:21
msgid "Our analysis showed that the RSS consumption for Quarkus 2.7 was about ~33MB while for Quarkus 2.13 it was about ~36MB, roughly a 10 % increase.  Below we see how we measured the RSS consumption for Quarkus 2.7.6.Final:"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:27
#, no-wrap
msgid ""
"$ getting-started/target/getting-started-1.0.0-SNAPSHOT-runner -Xmx64m\n"
"...\n"
"2023-07-21 10:13:11,304 INFO  [io.quarkus] (main) getting-started 1.0.0-SNAPSHOT native (powered by Quarkus 2.7.6.Final) started in 0.023s. Listening on: http://0.0.0.0:8080\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:30
#, no-wrap
msgid ""
"$ ps -p $(pidof getting-started-1.0.0-SNAPSHOT-runner) -o rss=\n"
"33024\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:34
msgid "Similarly, below we see how we measured the RSS consumption for Quarkus 2.13.4.Final: In our environment, the RSS consumption had gone up to about ~36M, roughly a 10% increase:"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:40
#, no-wrap
msgid ""
"$ getting-started/target/getting-started-1.0.0-SNAPSHOT-runner -Xmx64m\n"
"...\n"
"2023-07-21 10:24:38,529 INFO  [io.quarkus] (main) getting-started 1.0.0-SNAPSHOT native (powered by Quarkus 2.13.4.Final) started in 0.027s. Listening on: http://0.0.0.0:8080\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:43
#, no-wrap
msgid ""
"$ ps -p $(pidof getting-started-1.0.0-SNAPSHOT-runner) -o rss=\n"
"36608\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:49
msgid "Since Quarkus 2.7 and 2.13 used different GraalVM versions (21.3 vs 22.3), we first investigated whether the increase in the startup time and RSS consumption was due to a change in GraalVM.  This turned out to not be the case, as using the same GraalVM version on both Quarkus versions still resulted in similar differences."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:55
msgid "We also profiled the startup time in JVM mode, and although we could observe some slight increase in heap usage, the RSS increase was not apparent at runtime.  So, the challenge was to understand what was causing the RSS increase that seemed to only affect native mode and that was Quarkus specific."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:67
msgid "In native mode we needed to look for system calls that increased RSS, and investigate what caused them.  There are several system calls that can be used to allocate memory, e.g. `malloc`, `mmap`...etc, but when we analysed the system calls emitted on startup, we discovered that `mmap` calls were the prominent ones.  Following https://www.brendangregg.com/FlameGraphs/memoryflamegraphs.html[Brendan Greggâ€™s Memory Leak (and Growth) Flame Graphs guide] on a Linux environment, we were able to produce flamegraphs for the `mmap` system calls.  To obtain these flamegraphs, we capture the `sys_enter_mmap` system call events with `perf record`, and then we generate flamegraphs with the recorded data:"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:74
#, no-wrap
msgid ""
"$ sudo perf record -e syscalls:sys_enter_mmap --call-graph dwarf \\\n"
"  -- getting-started/target/getting-started-1.0.0-SNAPSHOT-runner -Xmx64m\n"
"...\n"
"2023-07-21 10:13:11,304 INFO  [io.quarkus] (main) getting-started 1.0.0-SNAPSHOT native (powered by Quarkus 2.7.6.Final) started in 0.023s. Listening on: http://0.0.0.0:8080\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:76
#, no-wrap
msgid "$ perf script -i perf.data > out.stacks\n"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:82
#, no-wrap
msgid ""
"$ /opt/FlameGraph/stackcollapse-perf.pl < out.stacks \\\n"
"  | /opt/FlameGraph/flamegraph.pl \\\n"
"   --color=mem \\\n"
"   --title=\"mmap Flame Graph\" \\\n"
"   --countname=\"calls\" > out.svg\n"
msgstr ""

#. type: delimited block =
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:89
msgid "The native executable above was created passing in `-Dquarkus.native.debug.enabled` and `-Dquarkus.native.additional-build-args=-H:-DeleteLocalSymbols` as extra build flags."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:105
msgid "`mmap` calls happen for a variety of reasons, but in the context of this blog post, we're interested in those `mmap` calls that are triggered by object allocations.  Not every object allocation triggers an `mmap` call.  Instead, each thread in SubstrateVM will allocate a heap chunk using `mmap` when the first object is allocated, and it will use this heap chunk as long as there's space for further objects allocated in the same thread.  When the heap chunk is full, the thread will request a new heap chunk using `mmap`.  This pattern is called thread-local allocation.  HotSpot has a similar feature as well, but there the heap chunk size is dynamically computed depending on multiple factors, while on SubstrateVM the size is fixed.  At the time of writing, the default heap chunk size is 1MB, but an upcoming change will make it 512KB instead."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:113
msgid "We describe the object allocation as fast when the thread has a heap chunk cached and there's enough space for the object.  We describe the object allocation as slow when the thread needs to request a new heap chunk via the `mmap` system call to satisfy the object allocation.  Slow allocations are the most interesting in this case, because they give us a rough indication of which allocations are pushing the number of heap chunks up, and therefore are pushing the RSS consumption up.  In SubstrateVM, stacktraces of the slow allocation path contain invocations to methods defined in the `com.oracle.svm.core.genscavenge.ThreadLocalAllocation` class that contain the `slowPathNew` prefix in their name .  E.g. `slowPathNewInstance` for plain objects or `slowPathNewArray` for arrays."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:123
msgid "The areas of interest in the flamegraphs are those stacktraces that contain `ApplicationImpl.doStart()` method call, because that's the method that is responsible for starting up Quarkus applications.  We want to find out how many slow path allocations are visible in these stacktraces, which are executed by the `main` thread.  Also, by looking at the stacktraces that cause these slow path allocations, we can get an idea of which components might be allocation heavy.  If you focus the flamegraph on that method, and then click on `Search` at the top right and type `slowPathNew`, you can observe which of the `sys_enter_mmap` system calls are related to native heap memory allocation."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:125
msgid "For Quarkus 2.7.6.Final, the flamegraph looks like this:"
msgstr ""

#. type: Positional ($1) AttributeList argument for macro 'image'
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:126
#, no-wrap
msgid "startup rss startup flamegraph for Quarkus 2.7.6.Final"
msgstr ""

#. type: Target for macro image
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:126
#, no-wrap
msgid "rss-before-mmap.svg"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:129
msgid "And here's a screenshot highlighting the stacktraces that contain slow path allocations:"
msgstr ""

#. type: Positional ($1) AttributeList argument for macro 'image'
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:130
#, no-wrap
msgid "slow path new allocations for Quarkus 2.7.6.Final"
msgstr ""

#. type: Target for macro image
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:130
#, no-wrap
msgid "rss-before-slowPathNew.png"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:133
msgid "Observing the number of stacktraces that contain `slowPathNew` invocations above, i.e. 2, we can say that the `main` thread in Quarkus 2.7.6.Final allocates roughly 2MB of heap chunks."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:135
msgid "For Quarkus 2.13.4.Final, the flamegraph looks like this:"
msgstr ""

#. type: Positional ($1) AttributeList argument for macro 'image'
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:136
#, no-wrap
msgid "startup rss startup flamegraph for Quarkus 2.13.4.Final"
msgstr ""

#. type: Target for macro image
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:136
#, no-wrap
msgid "rss-after-mmap.svg"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:139
msgid "Focusing on the same area, we observe that the `slowPathNew` stacktrace count is 5 in this case, so the `main` thread allocates roughly 5MB of heap chunks:"
msgstr ""

#. type: Positional ($1) AttributeList argument for macro 'image'
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:140
#, no-wrap
msgid "slow path new allocations for Quarkus 2.13.4.Final"
msgstr ""

#. type: Target for macro image
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:140
#, no-wrap
msgid "rss-after-slowPathNew.png"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:148
msgid "The increase in object allocation at runtime startup between these two Quarkus versions, combined with the idiosyncrasies of how thread local allocation works in SubstrateVM, is what was causing the increase in RSS consumption.  In other words, even though both HotSpot and SubstrateVM experience higher allocations, SubstrateVM's fixed thread-local allocation heap chunk sizes make this more apparent, compared to the dynamic thread-local allocation logic in HotSpot."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:154
msgid "Since then, improvements were made to the components that caused the extra object allocation.  We were able to detect the changes that had caused these extra allocations by looking at the components that appeared in the stacktrace leading to slow allocations, and inspecting updates that had happened in those components.  In this case, updates to the SmallRye configuration handling at startup caused the regression."
msgstr ""

#. type: delimited block =
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:163
msgid "The stacktraces that cause slow object allocations give us an approximation on the components that cause memory usage increase.  There could be situations where the stacktrace leading to a slow allocation is perfectly valid, but due to the non-deterministic nature of object allocation, the stacktrace just happens to be the one that caused a new heap chunk to be allocated.  However, if you see multiple stacktraces in the same area, that's probably a good hint that something in that area needs to be investigated."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:171
msgid "By Quarkus version 2.13.7.Final, the RSS consumption on startup was back to previous levels.  The RSS regression was introduced by the changes in https://github.com/quarkusio/quarkus/pull/26802#issue-1308798216[PR #26802], and the fixes in https://github.com/quarkusio/quarkus/pull/29408[PR #29408] and https://github.com/quarkusio/quarkus/pull/29842[PR #29842] brought it back down."
msgstr ""

#. type: Title ==
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:172
#, no-wrap
msgid "Performing the analysis with `ObjectAllocationInNewTLAB` JFR event"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:180
msgid "As newer versions of GraalVM implement https://github.com/oracle/graal/issues/5410[more and more JFR events] in native mode, it also becomes easier to analyse Quarkus application performance.  For instance the recent release of GraalVM for JDK 17/20 adds support for the `jdk.ObjectAllocationInNewTLAB` event, which would have highlighted the discrepancies in the Quarkus versions compared above.  Unfortunately, the Quarkus versions tested here are not compatible with this GraalVM version, but we can give it a go with the latest Quarkus version to see what comes out."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:182
msgid "First, we build the native Quarkus application with JFR support:"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:186
#, no-wrap
msgid "$ ./mvnw package -DskipTests -Dquarkus.native.monitoring=jfr -Dnative\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:191
msgid "To obtain `jdk.ObjectAllocationInNewTLAB` events, a custom JFC configuration file is required.  We use `jfr configure` to generate it:"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:195
#, no-wrap
msgid "$ $JAVA_HOME/bin/jfr configure jdk.ObjectAllocationInNewTLAB#enabled=true --output newtlab.jfc\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:198
msgid "Then, we start the Quarkus native executable with the necessary JFR flags:"
msgstr ""

#. type: delimited block -
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:204
#, no-wrap
msgid ""
"$ getting-started/target/getting-started-1.0.0-SNAPSHOT-runner -XX:+FlightRecorder -XX:StartFlightRecording=settings=newtlab.jfc,filename=recording.jfr -Xmx64m\n"
"...\n"
"2023-07-21 12:25:33,739 INFO  [io.quarkus] (main) getting-started 1.0.0-SNAPSHOT native (powered by Quarkus 3.2.1.Final) started in 0.019s. Listening on: http://0.0.0.0:8080\n"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:210
msgid "After shutting down Quarkus, we can use https://adoptium.net/jmc[Adoptium's Eclipse Mission Control] to visualize a flamegraph for all the `jdk.ObjectAllocationInNewTLAB` events.  We can also do a similar focus on `ApplicationImpl.doStart()` method to observe which slow path allocations get triggered from there:"
msgstr ""

#. type: Positional ($1) AttributeList argument for macro 'image'
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:211
#, no-wrap
msgid "new tlab events from ApplicationImpl.doStart() method Quarkus 3.2.1.Final"
msgstr ""

#. type: Target for macro image
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:211
#, no-wrap
msgid "jmc-new-tlab-event-from-doStart.png"
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:218
msgid "Looking at the flamegraph, we can count 7 stacktraces for slow path allocations for the `main` thread.  Whether this is a problem, or maybe code execution has shifted from another thread to `main`, would be something we would need to explore further and see if there's a regression."
msgstr ""

#. type: Plain text
#: upstream/_posts/2023-07-27-native-startup-rss-troubleshooting.adoc:223
msgid "If you encounter memory issues in your native applications, or any other type of performance issues, do not hesitate giving JFR a go.  Robert Toyonaga has written a couple of blog posts on the latest JFR additions, see link:/blog/profile-and-monitor-native-executables-with-jfr[here] to find out more."
msgstr ""
